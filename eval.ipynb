{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(r\"C:\\Users\\KHU\\Desktop\\무신사\\eval_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_link', 'processed_image'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KHU\\anaconda3\\envs\\clip\\Lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "model = model.to(device) # 모델을 디바이스로 이동\n",
    "\n",
    "# 텍스트 입력\n",
    "text = \"A cute puppy playing in the park\"\n",
    "\n",
    "# 텍스트 인코딩\n",
    "text_encoded = clip.tokenize([text]).to(device)\n",
    "text_features = model.encode_text(text_encoded).float()\n",
    "\n",
    "# 이미지 데이터셋 로드 및 특징 추출\n",
    "title_list = df['image_link'].tolist()\n",
    "image_processed = [img.to(device) for img in df['processed_image'].tolist()] # 이미지 텐서를 디바이스로 이동\n",
    "image_features = []\n",
    "cnt=0\n",
    "for image in image_processed:\n",
    "    image_features.append(model.encode_image(image).float())\n",
    "    cnt+=1\n",
    "    if(cnt>10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant image: https://image.msscdn.net/images/style/detail/41650/detail_41650_6629b7f3484ee_500.jpg\n"
     ]
    }
   ],
   "source": [
    "# 유사도 계산 및 최대값 찾기\n",
    "similarities = [torch.cosine_similarity(text_features, img_feat, dim=-1) for img_feat in image_features]\n",
    "max_idx = torch.argmax(torch.tensor(similarities))\n",
    "\n",
    "# 가장 관련된 이미지 출력\n",
    "print(f\"Most relevant image: {title_list[max_idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
